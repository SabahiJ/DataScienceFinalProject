##Python scripts for scraping & processing
import os
import time
import pandas as pd
from newsapi import NewsApiClient

# üîë Replace with your NewsAPI key (Keep it private!)
API_KEY = "your_api_key_here"

# Ensure the "data" directory exists
os.makedirs("data", exist_ok=True)

# Initialize NewsAPI client
newsapi = NewsApiClient(api_key=API_KEY)

# Define stocks (search terms)
stocks = ["Apple", "Microsoft", "Nvidia", "JPMorgan", "Goldman Sachs", "ExxonMobil", "Chevron", "S&P 500", "Nasdaq", "Dow Jones"]

news_data = []

# Function to fetch news articles
def fetch_news(stock):
    try:
        articles = newsapi.get_everything(q=stock, language="en", sort_by="publishedAt", page_size=10)

        for article in articles["articles"]:
            news_data.append([
                article["source"]["name"],  # News Source
                stock,  # Stock Name
                article["title"],  # Headline
                article["url"],  # News Link
                ""  # Sentiment Placeholder
            ])

        time.sleep(2)  # Avoid rate-limiting

    except Exception as e:
        print(f"‚ùå Failed to fetch news for {stock}: {e}")

# Fetch news for each stock
for stock in stocks:
    fetch_news(stock)

# Convert to DataFrame
news_df = pd.DataFrame(news_data, columns=["Source", "Stock", "Headline", "URL", "Sentiment"])

# Save to CSV
news_df.to_csv("data/financial_sentiment_dataset.csv", index=False)

print("‚úÖ News Data Collected! File saved to 'data/financial_sentiment_dataset.csv'.")



import pandas as pd
import re

# Load dataset
df = pd.read_csv("data/financial_sentiment_dataset.csv")

# Clean headlines (remove special characters, lowercasing)
df["Headline"] = df["Headline"].apply(lambda x: re.sub(r"[^a-zA-Z\s]", "", str(x)).lower())

# Save cleaned data
df.to_csv("data/cleaned_sentiment_dataset.csv", index=False)

